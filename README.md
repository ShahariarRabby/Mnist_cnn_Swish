<div class="postArticle-content js-postField js-notesSource js-trackedPost" data-post-id="62108f9463df" data-source="post_page" data-tracking-context="postPage" data-scroll="native"><section name="71f8" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h1 name="7137" id="7137" class="graf graf--h3 graf--leading graf--title">MNIST Kaggle submission with CNN Keras Swish activation</h1><p name="5687" id="5687" class="graf graf--p graf-after--h3">Last couple of weeks I saw some post about <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">Swish </a>activation by google brain. That was fun, people was talking about it and applied in some small and big neural network. So, I planed to make a kaggle submission with it.</p><p name="fdc3" id="fdc3" class="graf graf--p graf-after--p">The math behind <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a> is so simple. Just f(x) = x * sigmoid(x). According to <a href="https://arxiv.org/abs/1710.05941v1" data-href="https://arxiv.org/abs/1710.05941v1" class="markup--anchor markup--p-anchor" rel="nofollow noopener nofollow noopener" target="_blank">their paper</a>, the SWISH activation provides better performance than rectified linear units (ReLU(x)= max(0,x)), even when the hyperparameters are tuned for ReLU!</p><figure name="cbd5" id="cbd5" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 384px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 54.800000000000004%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*AVYIN3Vp5PfDQU6Q-bylWQ.png" data-width="1269" data-height="696" data-is-featured="true" data-action="zoom" data-action-value="1*AVYIN3Vp5PfDQU6Q-bylWQ.png" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*AVYIN3Vp5PfDQU6Q-bylWQ.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="39"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*AVYIN3Vp5PfDQU6Q-bylWQ.png" src="https://cdn-images-1.medium.com/max/1000/1*AVYIN3Vp5PfDQU6Q-bylWQ.png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*AVYIN3Vp5PfDQU6Q-bylWQ.png"&gt;</noscript></div></div></figure><p name="d0aa" id="d0aa" class="graf graf--p graf-after--figure">I have a Keras ReLU model that score 0.99457 on kaggle submission. I choose that exact model and Change all the ReLU activation to <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a>.And that model achieve 0.99671&nbsp;.</p><h3 name="844d" id="844d" class="graf graf--h3 graf-after--p">Making the Activation for&nbsp;keras</h3><p name="6179" id="6179" class="graf graf--p graf-after--h3">There is no direct impletation for <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a> in keras. So first step is to make a <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a> Activation for keras. Just 3 lines of code make it work.</p><pre name="4124" id="4124" class="graf graf--pre graf-after--p">from keras import backend as K<br>from keras.layers import Activationfrom <br>keras.utils.generic_utils import get_custom_objects</pre><pre name="29c7" id="29c7" class="graf graf--pre graf-after--pre">def swish(x):<br>    return (K.sigmoid(x) * x)</pre><pre name="16fe" id="16fe" class="graf graf--pre graf-after--pre">get_custom_objects().update({'swish': Activation(swish )})</pre><p name="7dba" id="7dba" class="graf graf--p graf-after--pre">Now just add <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a> as an activation</p><pre name="4311" id="4311" class="graf graf--pre graf-after--p">model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = ‘Same’, <br> activation =’swish’, input_shape = (28,28,1)))</pre><p name="348a" id="348a" class="graf graf--p graf-after--pre">And last layer as sigmoid</p><pre name="9a6f" id="9a6f" class="graf graf--pre graf-after--p">model.add(Dense(10, activation = "sigmoid"))</pre><h3 name="a786" id="a786" class="graf graf--h3 graf-after--pre">Accuracy Comparison</h3><p name="ef05" id="ef05" class="graf graf--p graf-after--h3">In term of accuracy i found that <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a> is doing better than ReLU. Make 90 position up in kaggle.</p><figure name="7ea1" id="7ea1" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 263px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 37.6%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*yQlKr7YvUNltsOGIMb29DA.png" data-width="996" data-height="374" data-action="zoom" data-action-value="1*yQlKr7YvUNltsOGIMb29DA.png" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*yQlKr7YvUNltsOGIMb29DA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="27"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*yQlKr7YvUNltsOGIMb29DA.png" src="https://cdn-images-1.medium.com/max/1000/1*yQlKr7YvUNltsOGIMb29DA.png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*yQlKr7YvUNltsOGIMb29DA.png"&gt;</noscript></div></div></figure><h3 name="3e03" id="3e03" class="graf graf--h3 graf-after--figure">Time Comparison</h3><p name="4fb8" id="4fb8" class="graf graf--p graf-after--h3">ReLU is more than 10 second faster than <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a> in each epoch on my Geforce 940mx. I know that <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a> calculate the sigmoid of input and multiply with the input. May be that take extra 10 second for each epoch.</p><figure name="0ce3" id="0ce3" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 467px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.7%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*FVE9VKKSBrfx9C9h2QQMaA.png" data-width="888" data-height="592" data-action="zoom" data-action-value="1*FVE9VKKSBrfx9C9h2QQMaA.png" data-scroll="native"><img src="https://cdn-images-1.medium.com/freeze/max/38/1*FVE9VKKSBrfx9C9h2QQMaA.png?q=20" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="49"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1000/1*FVE9VKKSBrfx9C9h2QQMaA.png" src="https://cdn-images-1.medium.com/max/1000/1*FVE9VKKSBrfx9C9h2QQMaA.png"><noscript class="js-progressiveMedia-inner">&lt;img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1000/1*FVE9VKKSBrfx9C9h2QQMaA.png"&gt;</noscript></div></div></figure><h3 name="fa0b" id="fa0b" class="graf graf--h3 graf-after--figure">Observation</h3><p name="c278" id="c278" class="graf graf--p graf-after--h3">After submission <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a> 90 position up my position. But that was just 0.002 more. And it’s take 20%–30% more time per epoch in GPU. There is another version of <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish</a> activation known as Swish_beta (f(x) = 2x*sigmoid(beta*x)). I hope that will work better than Normal Swish.</p><h3 name="04e5" id="04e5" class="graf graf--h3 graf-after--p">Resource</h3><p name="9d87" id="9d87" class="graf graf--p graf-after--h3"><a href="https://www.kaggle.com/shahariar/cnn-keras-swish-activation-acc-0-996-top-7" data-href="https://www.kaggle.com/shahariar/cnn-keras-swish-activation-acc-0-996-top-7" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank"><em class="markup--em markup--p-em">Kaggel kernel</em></a><em class="markup--em markup--p-em"> for this code</em></p><p name="6d5b" id="6d5b" class="graf graf--p graf-after--p"><a href="https://medium.com/@shahariarrabby/mnist-kaggle-submission-with-cnn-keras-switch-activation-62108f9463df" data-href="https://medium.com/@shahariarrabby/mnist-kaggle-submission-with-cnn-keras-switch-activation-62108f9463df" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Medium post</a> for this code</p><p name="6703" id="6703" class="graf graf--p graf-after--p">Original <a href="https://arxiv.org/abs/1710.05941" data-href="https://arxiv.org/abs/1710.05941" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">Swish Paper</a></p><p name="59bb" id="59bb" class="graf graf--p graf-after--p graf--trailing">If you find any bugs or having difficulty to understand the code, feel free to make a issue/pull in gihub or comment here.</p></div></div></section></div>
